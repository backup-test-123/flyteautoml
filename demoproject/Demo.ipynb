{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flyte Demo\n",
    "\n",
    "- Register all tasks\n",
    "- Create an orchasteration workflow by composing other workflows\n",
    "- Visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use our own staging environment for the live demo!\n",
    "import os\n",
    "os.environ['FLYTE_PLATFORM_URL'] = \"flyte-staging.lyft.net\"\n",
    "version = \"fake19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register existing tasks/workflows with the system\n",
    "from flytekit.clis.sdk_in_container.register import register_all, register_tasks_only\n",
    "import os \n",
    "from flytekit.configuration import set_flyte_config_file\n",
    "\n",
    "os.environ[\"FLYTE_INTERNAL_IMAGE\"] = \"docker.io/lyft/flytekubecondemo2019:c139801bf4a8bc0d78c2bf56a30d03cca9205a64\"\n",
    "set_flyte_config_file(\"staging.config\")\n",
    "os.environ[\"FLYTE_INTERNAL_CONFIGURATION_PATH\"] = \"/app/staging.config\"\n",
    "\n",
    "register_all(\"flytekubecondemo2019\", \"development\", [\"workflows\"], version=version, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrator Workflow\n",
    "\n",
    "- Use data preparation, training and evaluation workflows to compose an orchestrator worklfow\n",
    "- Kick of an execution and wait for completion\n",
    "- Visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchasterator_wf_version = version+\"-orchasterator-7\"\n",
    "\n",
    "# The Orchestrator Workflow\n",
    "import ujson\n",
    "from flytekit.common.tasks.task import SdkTask\n",
    "from flytekit.sdk.tasks import python_task, inputs, outputs\n",
    "from flytekit.sdk.types import Types\n",
    "from flytekit.sdk.workflow import workflow_class, Output, Input\n",
    "from workflows.classifier_evaluate_workflow import evaluate_lp\n",
    "from workflows.classifier_train_workflow import train_lp, DEFAULT_VALIDATION_DATA_RATIO, \\\n",
    "    DEFAULT_TRAINING_VALIDATION_CONFIG_FILE\n",
    "from workflows.data_preparation_workflow import data_prep\n",
    "from workflows.driver_workflow import pick_second\n",
    "\n",
    "DEFAULT_TRAINING_CONFIG_FILE = \"models/classifier/resnet50/configs/model_training_config_demo.json\"\n",
    "DEFAULT_EVALUATION_CONFIG_FILE = \"models/classifier/resnet50/configs/model_evaluation_config_demo.json\"\n",
    "\n",
    "\n",
    "# Consume a task from a different project\n",
    "# compute_confusion_matrix = SdkTask.fetch(\n",
    "#     project=\"kubecondemo2019-metrics\",\n",
    "#     domain=\"development\",\n",
    "#     name=\"demo_metrics.tasks.confusion_matrix.confusion_matrix\",\n",
    "#     version=\"66b463748f25ef71c8cd4eb3001f00eafb83efc6\",\n",
    "# )\n",
    "\n",
    "\n",
    "@workflow_class\n",
    "class Orchestrator(object):\n",
    "    # Define inputs\n",
    "    streams_external_storage_prefix = Input(Types.String, required=True)\n",
    "    streams_names = Input([Types.String], required=True)\n",
    "    stream_extension = Input(Types.String, default=\"avi\")\n",
    "\n",
    "    streams_metadata_path = Input(Types.String, required=True)\n",
    "    training_validation_config_json = Input(Types.Generic,\n",
    "                                            default=ujson.loads(open(DEFAULT_TRAINING_CONFIG_FILE).read()))\n",
    "    validation_data_ratio = Input(Types.Float, default=DEFAULT_VALIDATION_DATA_RATIO)\n",
    "    evaluation_config_json = Input(Types.Generic,\n",
    "                                   default=ujson.loads(open(DEFAULT_EVALUATION_CONFIG_FILE).read()))\n",
    "\n",
    "    # Define workflow steps\n",
    "    \n",
    "    # Call data prep workflow defined in this project\n",
    "    prepare = data_prep(\n",
    "        streams_external_storage_prefix=streams_external_storage_prefix,\n",
    "        streams_names=streams_names,\n",
    "        stream_extension=stream_extension)\n",
    "\n",
    "    # Call train workflow defined in this project\n",
    "    train = train_lp(\n",
    "        available_streams_names=prepare.outputs.streams_names_out,\n",
    "        available_streams_mpblobs=prepare.outputs.selected_frames_mpblobs,\n",
    "        streams_metadata_path=streams_metadata_path,\n",
    "        training_validation_config_json=training_validation_config_json,\n",
    "        validation_data_ratio=validation_data_ratio\n",
    "    )\n",
    "\n",
    "    # Call a task defined in this project\n",
    "    pick_second = pick_second(models=train.outputs.trained_models)\n",
    "    \n",
    "    # Call evaluate workflow defined in this project\n",
    "    evaluate = evaluate_lp(\n",
    "        available_streams_names=prepare.outputs.streams_names_out,\n",
    "        available_streams_mpblobs=prepare.outputs.selected_frames_mpblobs,\n",
    "        streams_metadata_path=streams_metadata_path,\n",
    "        evaluation_config_json=evaluation_config_json,\n",
    "        model=pick_second.outputs.second,\n",
    "        validation_data_ratio=1.0,\n",
    "    )\n",
    "\n",
    "    # Call compute_confusion_matrix task imported from a different project.\n",
    "#     confusion_matrix_task = compute_confusion_matrix(\n",
    "#         y_true=evaluate.outputs.ground_truths,\n",
    "#         y_pred=evaluate.outputs.predictions,\n",
    "#         title=\"Confusion Matrix\",\n",
    "#         normalize=True,\n",
    "#         classes=[\"busy\", \"clear\"],\n",
    "#     )\n",
    "\n",
    "    # Define workflow outputs\n",
    "    model = Output(pick_second.outputs.second, sdk_type=Types.Blob)\n",
    "    ground_truths = Output(evaluate.outputs.ground_truths, sdk_type=[Types.Integer])\n",
    "    predictions = Output(evaluate.outputs.predictions, sdk_type=[Types.Integer])\n",
    "#     confusion_matrix_image = Output(confusion_matrix_task.outputs.visual, sdk_type=Types.Blob)\n",
    "\n",
    "\n",
    "orchestrator_lp = Orchestrator.create_launch_plan()\n",
    "\n",
    "# Register the spec in the system\n",
    "Orchestrator.register(\"flytekubecondemo2019\", \"development\", \"Orchestrator\", orchasterator_wf_version)\n",
    "orchestrator_lp.register(\"flytekubecondemo2019\", \"development\", \"Orchestrator\", orchasterator_wf_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick of an execution\n",
    "execution = orchestrator_lp.execute(\"flytekubecondemo2019\", \"development\", inputs={\n",
    "    'streams_external_storage_prefix': 's3://lyft-modelbuilder/metadata/_FlyteKubeconDemo2019Dataset/streams',\n",
    "    'streams_names': [\"1537396038_cam-rgb-1\",\"1537396038_cam-rgb-2\",\"1537396662_cam-rgb-1\",\"1537396662_cam-rgb-2\",\"1537396790_cam-rgb-1\",\"1537396790_cam-rgb-2\",\"1537396942_cam-rgb-1\",\"1537396942_cam-rgb-2\",\"1538521877_cam-rgb-1\",\"1538521877_cam-rgb-2\",\"1538521964_cam-rgb-1\",\"1538521964_cam-rgb-2\",\"1538522195_cam-rgb-1\",\"1538522195_cam-rgb-2\",\"1538522386_cam-rgb-1\",\"1538522386_cam-rgb-2\",\"1538522615_cam-rgb-1\",\"1538522615_cam-rgb-2\",\"1538522881_cam-rgb-1\",\"1538522881_cam-rgb-2\",\"1538523052_cam-rgb-1\",\"1538523052_cam-rgb-2\",\"1538523280_cam-rgb-1\",\"1538523280_cam-rgb-2\",\"1538523741_cam-rgb-1\",\"1538523741_cam-rgb-2\",\"1538523916_cam-rgb-1\",\"1538523916_cam-rgb-2\",\"1538524089_cam-rgb-1\",\"1538524089_cam-rgb-2\",\"1539390982_cam-rgb-1\",\"1539390982_cam-rgb-2\",\"1539391169_cam-rgb-1\",\"1539391169_cam-rgb-2\",\"1539391321_cam-rgb-1\",\"1539391321_cam-rgb-2\",\"1539391462_cam-rgb-1\",\"1539391462_cam-rgb-2\",\"1539391643_cam-rgb-1\",\"1539391643_cam-rgb-2\",\"1539391807_cam-rgb-1\",\"1539391807_cam-rgb-2\",\"1539391941_cam-rgb-1\",\"1539391941_cam-rgb-2\",\"1539471715_cam-rgb-1\",\"1539471715_cam-rgb-2\",\"1539471904_cam-rgb-1\",\"1539471904_cam-rgb-2\",\"1539475636_cam-rgb-1\",\"1539475636_cam-rgb-2\"],\n",
    "    'streams_metadata_path': 's3://lyft-modelbuilder/metadata/_FlyteKubeconDemo2019Dataset/metadata/streams_metadata.json',\n",
    "})\n",
    "\n",
    "print(\"Started execution: {}\".format(execution.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.common.workflow_execution import SdkWorkflowExecution\n",
    "execution = SdkWorkflowExecution.fetch(\"flytekubecondemo2019\", \"development\", \"jnxxi2aone\")\n",
    "\n",
    "execution.wait_for_completion()\n",
    "print(\"Workflow produced {} outputs\".format(len(execution.outputs)))\n",
    "\n",
    "# Download the model locally to run predictions\n",
    "execution.outputs[\"model\"].download(\"model\", overwrite=True)\n",
    "print(\"Downloaded the generated model.\")\n",
    "\n",
    "# Load the model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"model\")\n",
    "print(\"Loaded the model. Ready to run predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "local_file = \"/tmp/cm-4.png\"\n",
    "execution.outputs[\"confusion_matrix_image\"].download(local_file, overwrite=True)\n",
    "Image(filename=local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def predict_and_render(imags_paths, model):\n",
    "    imgs = [image.load_img(img_path, target_size=[224, 224]) for img_path in imgs_paths]\n",
    "    xs = [image.img_to_array(img) for img in imgs]\n",
    "    xs = [np.expand_dims(x, axis=0) for x in xs]\n",
    "    xs = np.vstack(xs)\n",
    "    preds = model.predict(np.array(xs))\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(16,6))\n",
    "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        ax_x = i // 5\n",
    "        ax_y = i % 5\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            axes[ax_x, ax_y].spines[axis].set_linewidth(4.0)\n",
    "        if preds[i][1] > 0.06739821285009384: \n",
    "            plt.setp(axes[ax_x, ax_y].spines.values(), color='red')\n",
    "        else:\n",
    "            plt.setp(axes[ax_x, ax_y].spines.values(), color='green')\n",
    "        axes[ax_x, ax_y].imshow(imgs[i])\n",
    "\n",
    "\n",
    "imgs_paths = [os.path.join(\"demo_imgs\", img_path) for img_path in os.listdir(\"demo_imgs\")]\n",
    "predict_and_render(imgs_paths, model)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
